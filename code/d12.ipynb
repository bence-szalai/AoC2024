{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba42ee6c-7b5d-430d-a3e0-d4daea50788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0f2a0884-11c5-4542-ad06-784c379efba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_M(s):\n",
    "    M = []\n",
    "    for l in s[:-1].split('\\n'):\n",
    "        M.append(list(l))\n",
    "    return np.array(M)\n",
    "    \n",
    "def padding(M):\n",
    "    i = M.shape[0] + 2\n",
    "    j = M.shape[1] + 2\n",
    "    M_new = np.zeros(shape=(i, j))\n",
    "    M_new[1:-1, 1:-1] = M.copy()\n",
    "    return M_new        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "4d65ef8b-9a38-4caa-b681-1b5661a1b515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_convolution(input_array, filter_kernel):\n",
    "    \"\"\"\n",
    "    Applies a convolution on the input array using the given filter kernel.\n",
    "    \n",
    "    Args:\n",
    "    input_array (torch.Tensor): The input 2D array with shape (H, W).\n",
    "    filter_kernel (torch.Tensor): The 2D filter kernel with shape (kH, kW).\n",
    "    \n",
    "    Returns:\n",
    "    torch.Tensor: The result of the convolution operation.\n",
    "    \"\"\"\n",
    "    # Ensure the input array is a 4D tensor with shape (1, 1, H, W)\n",
    "    input_tensor = torch.from_numpy(input_array).unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, H, W)\n",
    "    \n",
    "    # Ensure the filter kernel is a 4D tensor with shape (1, 1, kH, kW)\n",
    "    kernel_tensor = torch.from_numpy(filter_kernel).unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, kH, kW)\n",
    "    \n",
    "    # Perform the 2D convolution\n",
    "    output_tensor = F.conv2d(input_tensor, kernel_tensor, padding=(\n",
    "        (filter_kernel.shape[0] - 1) // 2,\n",
    "        (filter_kernel.shape[1] - 1) // 2\n",
    "    )\n",
    "    )\n",
    "    \n",
    "    # Remove the batch and channel dimensions to return a simple 2D array\n",
    "    output_array = output_tensor.squeeze(0).squeeze(0)  # Shape: (H_out, W_out)\n",
    "    \n",
    "    return output_array.numpy()\n",
    "\n",
    "kernel_fil = np.array(\n",
    "    [[0, 1, 0],\n",
    "     [1, 1, 1],\n",
    "     [0, 1, 0]]\n",
    ").astype(float)\n",
    "\n",
    "kernel_neighbour = np.array(\n",
    "    [[0, 1, 0],\n",
    "     [1, 0, 1],\n",
    "     [0, 1, 0]]\n",
    ").astype(float)\n",
    "\n",
    "kernel_horizontal_up = np.array(\n",
    "    [[-1],\n",
    "    [1],\n",
    "    [0]]\n",
    ").astype(float)\n",
    "\n",
    "kernel_horizontal_down = np.array(\n",
    "    [[0],\n",
    "    [1],\n",
    "    [-1]]\n",
    ").astype(float)\n",
    "\n",
    "kernel_vertical_left = np.array(\n",
    "    [[-1, 1, 0]]\n",
    ").astype(float)\n",
    "\n",
    "kernel_vertical_right = np.array(\n",
    "    [[0, 1, -1]]\n",
    ").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "29246e76-4b5c-4086-9e1b-19f1bfec586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values_for_one_object(M, start, kernel_fil, kernel_neighbour):\n",
    "    plant = M[start]\n",
    "    M_fil = M.copy()\n",
    "    M_fil_prev = M.copy()\n",
    "    M_fil[start] = '1'\n",
    "    while (M_fil != M_fil_prev).sum()!=0:\n",
    "        M_current = (M_fil == '1').astype(float)\n",
    "        M_neighbours = apply_convolution(M_current, kernel_fil) > 0\n",
    "        M_same = (M == plant)\n",
    "        M_fil_prev = M_fil.copy()\n",
    "        M_fil[M_neighbours&M_same] = '1'\n",
    "    M_current = (M_fil == '1').astype(float)\n",
    "    area = int(M_current.sum())\n",
    "    M_edge = apply_convolution(M_current, kernel_neighbour)\n",
    "    perimeter = int(((4 - (M_edge * M_current)) * M_current).sum())\n",
    "    fil = M_fil == '1'\n",
    "    M_new = M.copy()\n",
    "    M_new[fil] = '0'\n",
    "    return area * perimeter, M_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bf572cc6-ae10-467c-8a6a-c89f2de7c043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(M, kernel_fil, kernel_neighbour):\n",
    "    A = []\n",
    "    for i in range(M.shape[0]):\n",
    "        A.append(['0' for x in range(M.shape[1])])\n",
    "    A = np.array(A)\n",
    "    scores = 0\n",
    "    while (M != A).sum() > 0:\n",
    "        start = np.where(M != '0')\n",
    "        start = start[0][0], start[1][0]\n",
    "        s, M = get_values_for_one_object(M, start, kernel_fil, kernel_neighbour)\n",
    "        scores += s\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "353abca8-66c9-4046-a41c-8f5548967e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1930"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'RRRRIICCFF\\nRRRRIICCCF\\nVVRRRCCFFF\\nVVRCCCJFFF\\nVVVVCJJCFE\\nVVIVCCJJEE\\nVVIIICJJEE\\nMIIIIIJJEE\\nMIIISIJEEE\\nMMMISSJEEE\\n'\n",
    "M = read_M(s)\n",
    "get_values(M, kernel_fil, kernel_neighbour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ff04cd98-913a-4732-aeab-f6997598f450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1465112"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/d12.txt') as fin:\n",
    "    s = fin.read()\n",
    "M = read_M(s)\n",
    "get_values(M, kernel_fil, kernel_neighbour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "f9d802cd-de1f-4a53-9b1a-67e2ebb6c3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values_for_one_object2(M, start, kernel_fil, kernel_neighbour):\n",
    "    plant = M[start]\n",
    "    M_fil = M.copy()\n",
    "    M_fil_prev = M.copy()\n",
    "    M_fil[start] = '1'\n",
    "    while (M_fil != M_fil_prev).sum()!=0:\n",
    "        M_current = (M_fil == '1').astype(float)\n",
    "        M_neighbours = apply_convolution(M_current, kernel_fil) > 0\n",
    "        M_same = (M == plant)\n",
    "        M_fil_prev = M_fil.copy()\n",
    "        M_fil[M_neighbours&M_same] = '1'\n",
    "    M_current = (M_fil == '1').astype(float)\n",
    "    area = int(M_current.sum())\n",
    "    M_edge = apply_convolution(M_current, kernel_neighbour)\n",
    "    sides = get_sides(M_current, kernel_horizontal_down, kernel_horizontal_up, kernel_vertical_left, kernel_vertical_right)\n",
    "    fil = M_fil == '1'\n",
    "    M_new = M.copy()\n",
    "    M_new[fil] = '0'\n",
    "    return area * sides, M_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "a46dd064-6a77-4225-a1d1-6a0435d53f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values2(M, kernel_fil, kernel_neighbour):\n",
    "    A = []\n",
    "    for i in range(M.shape[0]):\n",
    "        A.append(['0' for x in range(M.shape[1])])\n",
    "    A = np.array(A)\n",
    "    scores = 0\n",
    "    while (M != A).sum() > 0:\n",
    "        start = np.where(M != '0')\n",
    "        start = start[0][0], start[1][0]\n",
    "        s, M = get_values_for_one_object2(M, start, kernel_fil, kernel_neighbour)\n",
    "        scores += s\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "3bf79315-bf4e-426c-a226-baeb7aadbcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1206"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'RRRRIICCFF\\nRRRRIICCCF\\nVVRRRCCFFF\\nVVRCCCJFFF\\nVVVVCJJCFE\\nVVIVCCJJEE\\nVVIIICJJEE\\nMIIIIIJJEE\\nMIIISIJEEE\\nMMMISSJEEE\\n'\n",
    "M = read_M(s)\n",
    "get_values2(M, kernel_fil, kernel_neighbour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "7ff9f665-97d4-4949-a3cd-208b5afede17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "893790"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/d12.txt') as fin:\n",
    "    s = fin.read()\n",
    "M = read_M(s)\n",
    "get_values2(M, kernel_fil, kernel_neighbour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "080ea9f9-a032-403b-8408-256698b3db0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_current = (M_fil == '1').astype(float)\n",
    "M_hor1 = apply_convolution(M_current, kernel_horizontal_down) * M_current\n",
    "M_hor2 = apply_convolution(M_current, kernel_horizontal_up) * M_current\n",
    "M_ver1 = apply_convolution(M_current, kernel_vertical_left) * M_current\n",
    "M_ver2 = apply_convolution(M_current, kernel_vertical_right) * M_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "4e873a00-5357-4c9e-89be-863f47f52b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sides(M_current, kernel_horizontal_down, kernel_horizontal_up, kernel_vertical_left, kernel_vertical_right):\n",
    "    M_hor1 = apply_convolution(M_current, kernel_horizontal_down) * M_current\n",
    "    M_hor2 = apply_convolution(M_current, kernel_horizontal_up) * M_current\n",
    "    M_ver1 = apply_convolution(M_current, kernel_vertical_left) * M_current\n",
    "    M_ver2 = apply_convolution(M_current, kernel_vertical_right) * M_current\n",
    "    sides = 0\n",
    "    for i in range(M_hor1.shape[0]):\n",
    "        current = 0\n",
    "        for j in range(M_hor1.shape[1]):\n",
    "            if (current==0) & (M_hor1[i, j]==1):\n",
    "                sides+=1\n",
    "            current = M_hor1[i, j]\n",
    "    for i in range(M_hor2.shape[0]):\n",
    "        current = 0\n",
    "        for j in range(M_hor2.shape[1]):\n",
    "            if (current==0) & (M_hor2[i, j]==1):\n",
    "                sides+=1\n",
    "            current = M_hor2[i, j]\n",
    "    for j in range(M_ver1.shape[1]):\n",
    "        current = 0\n",
    "        for i in range(M_ver1.shape[0]):\n",
    "            if (current==0) & (M_ver1[i, j]==1):\n",
    "                sides+=1\n",
    "            current = M_ver1[i, j]\n",
    "    \n",
    "    for j in range(M_ver2.shape[1]):\n",
    "        current = 0\n",
    "        for i in range(M_ver2.shape[0]):\n",
    "            if (current==0) & (M_ver2[i, j]==1):\n",
    "                sides+=1\n",
    "            current = M_ver2[i, j]\n",
    "    return sides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "12dd83c5-c1f2-4f0d-b65d-4ff500039ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "29e4c263-49e1-4625-9a0c-5a6eb04d45d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (4 - (M_edge * M_current)) * M_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a03e3783-5c03-446a-84c1-3d0c3d504ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 3]), array([4, 2]))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(X == X.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "0e5842bc-6703-4bd5-acb6-6fc30ac64e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [-0., -0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., -0., -0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_hor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9e9ce1f0-d867-4ee9-bc00-7303ae56f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array(\n",
    "    [[0, 1, 0],\n",
    "     [1, 1, 1],\n",
    "     [0, 1, 0]]\n",
    ").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "936f43ef-149b-4e9d-bec3-53bf47e636e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_neighbour = np.array(\n",
    "    [[0, 1, 0],\n",
    "     [1, 0, 1],\n",
    "     [0, 1, 0]]\n",
    ").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "645c23f2-14ea-4d04-8c7c-d18780fb7c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'],\n",
       "       ['0', '1.0', '1.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',\n",
       "        '0.0', '0.0', '0'],\n",
       "       ['0', '1.0', '1.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',\n",
       "        '0.0', '0.0', '0'],\n",
       "       ['0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',\n",
       "        '0.0', '0.0', '0'],\n",
       "       ['0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',\n",
       "        '0.0', '0.0', '0'],\n",
       "       ['0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',\n",
       "        '0.0', '0.0', '0'],\n",
       "       ['0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',\n",
       "        '0.0', '0.0', '0'],\n",
       "       ['0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',\n",
       "        '0.0', '0.0', '0'],\n",
       "       ['0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',\n",
       "        '0.0', '0.0', '0'],\n",
       "       ['0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',\n",
       "        '0.0', '0.0', '0'],\n",
       "       ['0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',\n",
       "        '0.0', '0.0', '0'],\n",
       "       ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']],\n",
       "      dtype='<U21')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "374357ae-7faa-4c9c-a3b3-60cac7230d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = M_current.copy()\n",
    "filter_kernel = kernel.copy()\n",
    "input_tensor = torch.from_numpy(input_array).unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, H, W)\n",
    "    \n",
    "    # Ensure the filter kernel is a 4D tensor with shape (1, 1, kH, kW)\n",
    "kernel_tensor = torch.from_numpy(filter_kernel).unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, kH, kW)\n",
    "output_tensor = F.conv2d(input_tensor, kernel_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9a12f06d-b9c7-4fb8-b59e-34ba80498d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "292782bf-3df6-4061-a56f-506de0f51199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_object(M, start):\n",
    "    plant = M[start]\n",
    "    M_fil = M.copy()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f418a715-e65d-4538-8b76-a18b93ddc37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1359d8850>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((M == 'R'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4792a987-4d86-451d-9093-3a7c99dbb32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Array:\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "\n",
      "Filter Kernel:\n",
      "tensor([[ 1.,  0., -1.],\n",
      "        [ 1.,  0., -1.],\n",
      "        [ 1.,  0., -1.]])\n",
      "\n",
      "Convolution Output:\n",
      "tensor([[-6.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def apply_convolution(input_array, filter_kernel):\n",
    "    \"\"\"\n",
    "    Applies a convolution on the input array using the given filter kernel.\n",
    "    \n",
    "    Args:\n",
    "    input_array (torch.Tensor): The input 2D array with shape (H, W).\n",
    "    filter_kernel (torch.Tensor): The 2D filter kernel with shape (kH, kW).\n",
    "    \n",
    "    Returns:\n",
    "    torch.Tensor: The result of the convolution operation.\n",
    "    \"\"\"\n",
    "    # Ensure the input array is a 4D tensor with shape (1, 1, H, W)\n",
    "    input_tensor = input_array.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, H, W)\n",
    "    \n",
    "    # Ensure the filter kernel is a 4D tensor with shape (1, 1, kH, kW)\n",
    "    kernel_tensor = filter_kernel.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, kH, kW)\n",
    "    \n",
    "    # Perform the 2D convolution\n",
    "    output_tensor = F.conv2d(input_tensor, kernel_tensor)\n",
    "    \n",
    "    # Remove the batch and channel dimensions to return a simple 2D array\n",
    "    output_array = output_tensor.squeeze(0).squeeze(0)  # Shape: (H_out, W_out)\n",
    "    \n",
    "    return output_array\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a simple 2D input array (image)\n",
    "    input_array = torch.tensor([[1.0, 2.0, 3.0],\n",
    "                                [4.0, 5.0, 6.0],\n",
    "                                [7.0, 8.0, 9.0]])\n",
    "    \n",
    "    # Create a simple 2D filter kernel (like an edge-detection kernel)\n",
    "    filter_kernel = torch.tensor([[1.0, 0.0, -1.0],\n",
    "                                  [1.0, 0.0, -1.0],\n",
    "                                  [1.0, 0.0, -1.0]])\n",
    "    \n",
    "    # Run the convolution\n",
    "    output = apply_convolution(input_array, filter_kernel)\n",
    "    \n",
    "    print(\"Input Array:\")\n",
    "    print(input_array)\n",
    "    print(\"\\nFilter Kernel:\")\n",
    "    print(filter_kernel)\n",
    "    print(\"\\nConvolution Output:\")\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4afe4a5-08b7-40c8-bc23-3fc058b8eb97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch-metal)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
